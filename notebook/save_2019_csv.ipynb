{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layering: divide the data into N layers, make sure every layer has the same distribution of 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load 2019 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('../data/water/txt/2019waterDataTraining.txt',delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "Time = np.zeros(df.shape[0]).astype(\"str\")\n",
    "for i in range(len(df)):\n",
    "    Time[i] = df['index'][i]+\" \"+ df['Time'][i]\n",
    "df['Time'] = Time\n",
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering\n",
    "\n",
    "\n",
    "It looks like we have 14 columns to help us predict our classification. We will drop fnlwgt and education and then convert our categorical features to dummy variables. We will also convert our label to 0 and 1 where 1 means the person made more than $50k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_columns = ['Time']\n",
    "continuous_features = ['Tp', 'pH', 'Cond', 'Turb', 'SAC', 'PFM']\n",
    "cat_features =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df_dummies = pd.get_dummies(df, columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df_dummies.drop(drop_columns, 1, inplace=True)\n",
    "# delte NA datas\n",
    "all_df_dummies = all_df_dummies.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132212, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_df_dummies.drop(['Event'], axis=1) # Series\n",
    "y_train = all_df_dummies['Event'].apply(lambda x: 0 if x == False else 1) # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([X_train,y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    132003\n",
       "1       209\n",
       "Name: Event, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('../data/water/csv/train2019.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"============ layer sampling ============\")\n",
    "# train_layer = Layering(train, kf)\n",
    "# array = train_layer.values\n",
    "# X_train = array[:, 0:-1] # ndarray\n",
    "# y_train = array[:, -1] # ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, y_train, test_size=valid_size,\n",
    "#                                                 stratify = y_train, random_state = random_seed)\n",
    "# # stratify： 按正负样本原始比例random_seed分配给train 和 valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do somte sampling on the train data to solve data imblance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_oversampled, y_train_oversampled = Smoter(X_tr, y_tr, is_random=True)\n",
    "# print(\"============ SMOTE ============\")\n",
    "# print(\"train: %d, contains %.4f of 0 , after SMOTE: train: %d contains %.4f of 1\" %(X_train.shape[0], (y_train == 0).sum()/y_train.shape[0], X_train_oversampled.shape[0], (y_train_oversampled == 0).sum()/y_train_oversampled.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize the train and valid\n",
    "\n",
    "fulfill the Na with median, then standardized the data, output type ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "#                            ('std_scaler', preprocessing.StandardScaler()),])\n",
    "# X_train_oversampled = clean_pipeline.fit_transform(X_train_oversampled)\n",
    "# X_vld = clean_pipeline.fit_transform(X_vld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer y into probability vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train_oversampled_pro = np.zeros([y_train_oversampled.shape[0], 2])\n",
    "# for i in range(len(y_train_oversampled)):\n",
    "#     if y_train_oversampled[i] == 1:\n",
    "#         y_train_oversampled_pro[i] = np.array([0, 1])\n",
    "#     else:\n",
    "#         y_train_oversampled_pro[i] = np.array([1, 0])\n",
    "# y_train_oversampled = y_train_oversampled_pro    \n",
    "\n",
    "# y_vld_pro = np.zeros([y_vld.shape[0], 2])\n",
    "# for i in range(len(y_vld)):\n",
    "#     if y_vld[i] == 1:\n",
    "#         y_vld_pro[i] = np.array([0, 1])\n",
    "#     else:\n",
    "#         y_vld_pro[i] = np.array([1, 0])\n",
    "# y_vld = y_vld_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load 2017 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = open(\"../data/water/txt/2018waterDataTesting.txt\").readlines()\n",
    "num_lines = len(lines) - 1\n",
    "\n",
    "X_test = np.ones((num_lines, 9))\n",
    "y_test = np.ones((num_lines, 1))\n",
    "flag = 0\n",
    "\n",
    "lines = np.delete(lines, 0, axis = 0)\n",
    "i = 0\n",
    "\n",
    "for line in lines:\n",
    "    data_line = line.split()\n",
    "    feature = data_line[2:11]\n",
    "    for k in range(9):\n",
    "        if feature[k] == 'NA':\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 1:\n",
    "        flag = 0\n",
    "        continue    # jump out of the loop\n",
    "    X_test[i] = feature    \n",
    "    if data_line[11] == 'FALSE':\n",
    "        y_test[i] = 0\n",
    "    elif data_line[11] == 'TRUE':\n",
    "        y_test[i] = 1\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# X_test = clean_pipeline.fit_transform(X_test) \n",
    "\n",
    "test = np.concatenate([X_test, y_test], axis=1)\n",
    "\n",
    "# y_test_pro = np.zeros([y_test.shape[0], 2])\n",
    "# for i in range(len(y_test)):\n",
    "#     if y_test[i] == 1:\n",
    "#         y_test_pro[i] = np.array([0, 1])\n",
    "#     else:\n",
    "#         y_test_pro[i] = np.array([1, 0])\n",
    "# y_test = y_test_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tp</th>\n",
       "      <th>Cl</th>\n",
       "      <th>pH</th>\n",
       "      <th>Redox</th>\n",
       "      <th>Leit</th>\n",
       "      <th>Trueb</th>\n",
       "      <th>Cl_2</th>\n",
       "      <th>Fm</th>\n",
       "      <th>Fm_2</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.38</td>\n",
       "      <td>755.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.38</td>\n",
       "      <td>755.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.38</td>\n",
       "      <td>755.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.37</td>\n",
       "      <td>755.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.38</td>\n",
       "      <td>755.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tp    Cl    pH  Redox   Leit  Trueb   Cl_2      Fm    Fm_2  EVENT\n",
       "0  4.4  0.14  8.38  755.0  232.0  0.009  0.110  1428.0  1020.0    0.0\n",
       "1  4.4  0.14  8.38  755.0  232.0  0.009  0.111  1436.0  1018.0    0.0\n",
       "2  4.4  0.14  8.38  755.0  232.0  0.014  0.113  1471.0  1019.0    0.0\n",
       "3  4.4  0.14  8.37  755.0  232.0  0.015  0.111  1457.0  1015.0    0.0\n",
       "4  4.4  0.14  8.38  755.0  232.0  0.013  0.111  1476.0  1019.0    0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(test, columns =['Tp', 'Cl', 'pH', 'Redox', 'Leit', 'Trueb', 'Cl_2', 'Fm', 'Fm_2', 'EVENT'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('../data/water/csv/test2018.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
