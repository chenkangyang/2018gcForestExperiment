{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### somte sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Smoter(X, y, is_random=False):\n",
    "    if is_random == True:\n",
    "        # random_lst = list(np.random.randint(0, 1000, 4))\n",
    "        sm = SMOTE(random_state=random_seed)\n",
    "    elif is_random == False:\n",
    "        sm = SMOTE(random_state=0)\n",
    "\n",
    "    # sm = SMOTE(random_state=random_lst[2])\n",
    "    X_smote, y_smote = sm.fit_sample(X, y)\n",
    "\n",
    "    return X_smote, y_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(true, pred):\n",
    "    # compute accuracy, precision and recall\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(0, len(pred)):\n",
    "        if pred[i] == true[i] and true[i] == 1:\n",
    "            TP += 1\n",
    "        elif pred[i] == true[i] and true[i] == 0:\n",
    "            TN += 1\n",
    "        elif pred[i] != true[i] and true[i] == 0:\n",
    "            FP += 1\n",
    "        elif pred[i] != true[i] and true[i] == 1:\n",
    "            FN += 1\n",
    "\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "    \n",
    "    print('TP=',TP,'FP=',FP,'TN=',TN,'FN=',FN)\n",
    "    F1 = 2*precision*recall / (precision + recall)\n",
    "    print(\"precision\", precision,\"\\nrecall\", recall,\"\\naccuracy\", accuracy)\n",
    "    print('F1=',F1)\n",
    "    return F1, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch\n",
    "\n",
    "combine serveral datasâ€˜ features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Batch(X, y, size):\n",
    "    batch_size = size\n",
    "\n",
    "    X_trim = X\n",
    "    y_trim = y\n",
    "\n",
    "    if len(X) % batch_size != 0:\n",
    "        extra_num = len(X) % batch_size\n",
    "        X_trim = np.delete(X, range(len(X) - extra_num, len(X)), axis = 0)\n",
    "        y_trim = np.delete(y, range(len(y) - extra_num, len(y)), axis = 0)\n",
    "\n",
    "    X_batch = np.split(X_trim, len(X_trim)/batch_size)\n",
    "    y_batch = np.split(y_trim, len(y_trim)/batch_size)\n",
    "\n",
    "    num_batch = 0\n",
    "\n",
    "    for each_batch in X_batch:\n",
    "        X_batch[num_batch] = np.reshape(X_batch[num_batch], (9*batch_size))\n",
    "        y_batch[num_batch] = y_batch[num_batch][-1]\n",
    "        num_batch += 1\n",
    "\n",
    "    X_batch = np.array(X_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "test_size = 0.33\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data\n",
    "\n",
    "fulfill the Na with median, then standardized the data, output type ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GcForest\n",
    "\n",
    "## test gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 2018 Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/water/csv/test2018.csv\")\n",
    "\n",
    "X_test = test.values[:, 0:-1]\n",
    "y_test = test.values[:, -1]\n",
    "\n",
    "X_test = clean_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. test gcForest on 2018 Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "[ 2019-03-11 19:30:35,630][cascade_classifier.transform] X_groups_test.shape=[(139566, 9)]\n",
      "[ 2019-03-11 19:30:35,638][cascade_classifier.transform] group_dims=[9]\n",
      "[ 2019-03-11 19:30:35,639][cascade_classifier.transform] X_test.shape=(139566, 9)\n",
      "[ 2019-03-11 19:30:35,650][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(139566, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= 2018 datasets' results on test =============\n",
      "TP= 24544 FP= 0 TN= 112757 FN= 2265\n",
      "precision 1.0 \n",
      "recall 0.9155134469767615 \n",
      "accuracy 0.983771119040454\n",
      "F1= 0.955893521313263\n"
     ]
    }
   ],
   "source": [
    "with open(\"../pkl/2018_gc.pkl\", \"rb\") as f:\n",
    "    gc = pickle.load(f)\n",
    "    y_test_pred = gc.predict(X_test)\n",
    "    print(\"============= 2018 datasets' results on test =============\")\n",
    "    evaluate(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. test GcForest on 2018 batched test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test_batch, y_test_batch = Batch(X_test, y_test, batch_size)\n",
    "    \n",
    "# with open(\"../pkl/2018_test_batch.pkl\", \"rb\") as f:\n",
    "#     gc = pickle.load(f)\n",
    "#     y_test_pred = gc.predict(X_test_batch)\n",
    "#     print(\"============= 2017 datasets' results on %d batched test =============\" %(batch_size))\n",
    "#     evaluate(y_test_batch, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
