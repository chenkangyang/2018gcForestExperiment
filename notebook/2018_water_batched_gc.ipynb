{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### somte sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smoter(X, y, is_random=False):\n",
    "    if is_random == True:\n",
    "        # random_lst = list(np.random.randint(0, 1000, 4))\n",
    "        sm = SMOTE(random_state=random_seed)\n",
    "    elif is_random == False:\n",
    "        sm = SMOTE(random_state=0)\n",
    "\n",
    "    # sm = SMOTE(random_state=random_lst[2])\n",
    "    X_smote, y_smote = sm.fit_sample(X, y)\n",
    "\n",
    "    return X_smote, y_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true, pred):\n",
    "    # compute accuracy, precision and recall\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(0, len(pred)):\n",
    "        if pred[i] == true[i] and true[i] == 1:\n",
    "            TP += 1\n",
    "        elif pred[i] == true[i] and true[i] == 0:\n",
    "            TN += 1\n",
    "        elif pred[i] != true[i] and true[i] == 0:\n",
    "            FP += 1\n",
    "        elif pred[i] != true[i] and true[i] == 1:\n",
    "            FN += 1\n",
    "\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "    \n",
    "    print('TP=',TP,'FP=',FP,'TN=',TN,'FN=',FN)\n",
    "    F1 = 2*precision*recall / (precision + recall)\n",
    "    print(\"precision\", precision,\"\\nrecall\", recall,\"\\naccuracy\", accuracy)\n",
    "    print('F1=',F1)\n",
    "    return F1, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch\n",
    "\n",
    "combine serveral datasâ€˜ features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch(X, y, size):\n",
    "    batch_size = size\n",
    "\n",
    "    X_trim = X\n",
    "    y_trim = y\n",
    "\n",
    "    if len(X) % batch_size != 0:\n",
    "        extra_num = len(X) % batch_size\n",
    "        X_trim = np.delete(X, range(len(X) - extra_num, len(X)), axis = 0)\n",
    "        y_trim = np.delete(y, range(len(y) - extra_num, len(y)), axis = 0)\n",
    "\n",
    "    X_batch = np.split(X_trim, len(X_trim)/batch_size)\n",
    "    y_batch = np.split(y_trim, len(y_trim)/batch_size)\n",
    "\n",
    "    num_batch = 0\n",
    "\n",
    "    for each_batch in X_batch:\n",
    "        X_batch[num_batch] = np.reshape(X_batch[num_batch], (9*batch_size))\n",
    "        y_batch[num_batch] = y_batch[num_batch][-1]\n",
    "        num_batch += 1\n",
    "\n",
    "    X_batch = np.array(X_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gc_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy_config():\n",
    "    config = {}\n",
    "    ca_config = {}\n",
    "    ca_config[\"random_state\"] = random_seed\n",
    "    ca_config[\"max_layers\"] = 10\n",
    "    ca_config[\"early_stopping_rounds\"] = 3\n",
    "    ca_config[\"n_classes\"] = 2\n",
    "    ca_config[\"estimators\"] = []\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"RandomForestClassifier\", \"n_estimators\": 10, \"max_depth\": None, \"n_jobs\": -1})\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"ExtraTreesClassifier\", \"n_estimators\": 10, \"max_depth\": None, \"n_jobs\": -1})\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"LogisticRegression\"})\n",
    "    config[\"cascade\"] = ca_config\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "test_size = 0.33\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('../data/water/txt/2018waterDataTraining.txt',delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "Time = np.zeros(df.shape[0]).astype(\"str\")\n",
    "for i in range(len(df)):\n",
    "    Time[i] = df['index'][i]+\" \"+ df['Time'][i]\n",
    "df['Time'] = Time\n",
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "\n",
    "\n",
    "It looks like we have 14 columns to help us predict our classification. We will drop fnlwgt and education and then convert our categorical features to dummy variables. We will also convert our label to 0 and 1 where 1 means the person made more than $50k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Time']\n",
    "continuous_features = ['Tp', 'Cl', 'pH', 'Redox', 'Leit', 'Trueb', 'Cl_2', 'Fm', 'Fm_2']\n",
    "cat_features =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_dummies = pd.get_dummies(df, columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_dummies.drop(drop_columns, 1, inplace=True)\n",
    "# delte NA datas\n",
    "all_df_dummies = all_df_dummies.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_df_dummies.drop(['EVENT'], axis=1) # Series\n",
    "y = all_df_dummies['EVENT'].apply(lambda x: 0 if x == False else 1) # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([X,y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tp</th>\n",
       "      <th>Cl</th>\n",
       "      <th>pH</th>\n",
       "      <th>Redox</th>\n",
       "      <th>Leit</th>\n",
       "      <th>Trueb</th>\n",
       "      <th>Cl_2</th>\n",
       "      <th>Fm</th>\n",
       "      <th>Fm_2</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.36</td>\n",
       "      <td>749.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.36</td>\n",
       "      <td>749.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.35</td>\n",
       "      <td>749.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.117</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.35</td>\n",
       "      <td>749.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.35</td>\n",
       "      <td>749.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tp    Cl    pH  Redox   Leit  Trueb   Cl_2      Fm   Fm_2  EVENT\n",
       "0  6.5  0.17  8.36  749.0  211.0  0.011  0.118  1677.0  695.0      0\n",
       "1  6.5  0.17  8.36  749.0  211.0  0.011  0.118  1561.0  696.0      0\n",
       "2  6.5  0.17  8.35  749.0  211.0  0.011  0.117  1581.0  696.0      0\n",
       "3  6.5  0.17  8.35  749.0  211.0  0.011  0.118  1579.0  693.0      0\n",
       "4  6.5  0.17  8.35  749.0  211.0  0.011  0.118  1567.0  689.0      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = data_all.values\n",
    "X = array[:, 0:-1] # ndarray\n",
    "y = array[:, -1] # ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_valid_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ train_valid_split ============\n",
      "train: 92809, valid: 45712\n"
     ]
    }
   ],
   "source": [
    "print(\"============ train_valid_split ============\")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=test_size, stratify=y, random_state=random_seed)\n",
    "print(\"train: %d, valid: %d\" %(X_train.shape[0], X_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data before somte\n",
    "\n",
    "fulfill the Na with median, then standardized the data, output type ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])\n",
    "X_train = clean_pipeline.fit_transform(X_train)\n",
    "X_valid = clean_pipeline.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do somte sampling on the train data to solve data imblance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ SMOTE ============\n",
      "train: 92809, contains 0.9875 of 0 , after SMOTE: train: 183306 contains 0.5000 of 1\n"
     ]
    }
   ],
   "source": [
    "X_train_oversampled, y_train_oversampled = Smoter(X_train, y_train, is_random=True)\n",
    "print(\"============ SMOTE ============\")\n",
    "print(\"train: %d, contains %.4f of 0 , after SMOTE: train: %d contains %.4f of 1\" %(X_train.shape[0], (y_train == 0).sum()/y_train.shape[0], X_train_oversampled.shape[0], (y_train_oversampled == 0).sum()/y_train_oversampled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled_batch, y_train_oversampled_batch = Batch(X_train_oversampled, y_train_oversampled, batch_size)\n",
    "X_train_batch, y_train_batch = Batch(X_train, y_train, batch_size)\n",
    "X_valid_batch, y_valid_batch = Batch(X_valid, y_valid, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GcForest\n",
    "\n",
    "## train gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.train GcForest on oversampled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:49:20,081][cascade_classifier.fit_transform] X_groups_train.shape=[(183306, 9)],y_train.shape=(183306,),X_groups_test.shape=no_test,y_test.shape=no_test\n",
      "[ 2018-11-28 16:49:20,097][cascade_classifier.fit_transform] group_dims=[9]\n",
      "[ 2018-11-28 16:49:20,099][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-11-28 16:49:20,102][cascade_classifier.fit_transform] group_ends=[9]\n",
      "[ 2018-11-28 16:49:20,103][cascade_classifier.fit_transform] X_train.shape=(183306, 9),X_test.shape=(0, 9)\n",
      "[ 2018-11-28 16:49:20,120][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(183306, 9), X_cur_test.shape=(0, 9)\n",
      "[ 2018-11-28 16:49:21,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=99.98%\n",
      "[ 2018-11-28 16:49:22,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=99.98%\n",
      "[ 2018-11-28 16:49:23,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=99.98%\n",
      "[ 2018-11-28 16:49:24,250][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=99.98%\n",
      "[ 2018-11-28 16:49:25,213][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=99.98%\n",
      "[ 2018-11-28 16:49:25,219][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=99.98%\n",
      "[ 2018-11-28 16:49:25,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:26,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:26,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:27,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:27,559][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:27,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:27,931][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_0.predict)=81.73%\n",
      "[ 2018-11-28 16:49:28,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_1.predict)=81.79%\n",
      "[ 2018-11-28 16:49:28,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_2.predict)=81.83%\n",
      "[ 2018-11-28 16:49:28,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_3.predict)=81.47%\n",
      "[ 2018-11-28 16:49:29,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_4.predict)=81.66%\n",
      "[ 2018-11-28 16:49:29,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_cv.predict)=81.70%\n",
      "[ 2018-11-28 16:49:29,132][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=99.99%\n",
      "[ 2018-11-28 16:49:29,157][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(183306, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2018-11-28 16:49:29,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:30,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:30,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:31,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=100.00%\n",
      "[ 2018-11-28 16:49:31,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:31,563][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:31,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:32,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:32,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:33,042][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:33,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:33,410][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:34,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:34,904][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:35,640][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:36,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_3.predict)=99.98%\n",
      "[ 2018-11-28 16:49:37,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:37,013][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:37,019][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.99%\n",
      "[ 2018-11-28 16:49:37,029][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(183306, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2018-11-28 16:49:37,550][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:38,011][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:38,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=100.00%\n",
      "[ 2018-11-28 16:49:38,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:39,394][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=99.98%\n",
      "[ 2018-11-28 16:49:39,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:39,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:40,171][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:40,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:40,885][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:41,244][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_4.predict)=99.98%\n",
      "[ 2018-11-28 16:49:41,249][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:41,969][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:42,587][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:43,201][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_2.predict)=99.98%\n",
      "[ 2018-11-28 16:49:43,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:44,364][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:44,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:44,374][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.99%\n",
      "[ 2018-11-28 16:49:44,384][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(183306, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2018-11-28 16:49:44,917][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_0.predict)=99.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:49:45,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:45,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:46,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:46,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:46,733][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:47,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:47,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:48,148][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:48,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_3.predict)=99.98%\n",
      "[ 2018-11-28 16:49:49,051][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:49,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:49,808][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:50,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_1.predict)=99.98%\n",
      "[ 2018-11-28 16:49:51,041][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:51,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:52,668][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:52,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:52,678][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.99%\n",
      "[ 2018-11-28 16:49:52,687][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(183306, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2018-11-28 16:49:53,307][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:53,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:49:54,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_2.predict)=99.98%\n",
      "[ 2018-11-28 16:49:55,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:55,578][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:55,587][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:56,105][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:56,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_1.predict)=99.98%\n",
      "[ 2018-11-28 16:49:56,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:49:57,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:49:58,135][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:49:58,145][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:49:58,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_0.predict)=99.99%\n",
      "[ 2018-11-28 16:49:59,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_1.predict)=99.99%\n",
      "[ 2018-11-28 16:50:00,614][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_2.predict)=99.99%\n",
      "[ 2018-11-28 16:50:01,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_3.predict)=99.99%\n",
      "[ 2018-11-28 16:50:02,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_4.predict)=99.99%\n",
      "[ 2018-11-28 16:50:02,257][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_cv.predict)=99.99%\n",
      "[ 2018-11-28 16:50:02,263][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=99.99%\n",
      "[ 2018-11-28 16:50:02,264][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=99.99%, accuracy_test=0.00%\n"
     ]
    }
   ],
   "source": [
    "config = get_toy_config()\n",
    "gc = GCForest(config)\n",
    "\n",
    "X_train_enc = gc.fit_transform(X_train_oversampled, y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump\n",
    "with open(\"../pkl/2018_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gc, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open(\"../pkl/2018_test.pkl\", \"rb\") as f:\n",
    "    gc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test GcForest on valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:02,340][cascade_classifier.transform] X_groups_test.shape=[(45712, 9)]\n",
      "[ 2018-11-28 16:50:02,345][cascade_classifier.transform] group_dims=[9]\n",
      "[ 2018-11-28 16:50:02,347][cascade_classifier.transform] X_test.shape=(45712, 9)\n",
      "[ 2018-11-28 16:50:02,352][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(45712, 9)\n",
      "[ 2018-11-28 16:50:03,435][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(45712, 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_valid, 1 contains:  0.012469373468673434\n",
      "y_valid_pred, 1 contains:  0.012469373468673434\n",
      "============= 2018 datasets' results on valid =============\n",
      "TP= 559 FP= 11 TN= 45131 FN= 11\n",
      "precision 0.980701754385965 \n",
      "recall 0.980701754385965 \n",
      "accuracy 0.9995187259362969\n",
      "F1= 0.980701754385965\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = gc.predict(X_valid)\n",
    "\n",
    "y_valid_nonezero = np.count_nonzero(y_valid)\n",
    "y_valid_pred_nonezero = np.count_nonzero(y_valid_pred)\n",
    "\n",
    "print(\"y_valid, 1 contains: \", y_valid_nonezero/len(y_valid))\n",
    "print(\"y_valid_pred, 1 contains: \", y_valid_pred_nonezero/len(y_valid_pred))\n",
    "\n",
    "print(\"============= 2018 datasets' results on valid =============\")\n",
    "gc_f1, gc_accraucy, gc_precision, gc_recall = evaluate(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 2018 Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(\"../data/water/txt/2018waterDataTesting.txt\").readlines()\n",
    "num_lines = len(lines) - 1\n",
    "\n",
    "X_test = np.ones((num_lines, 9))\n",
    "y_test = np.ones((num_lines, 1))\n",
    "flag = 0\n",
    "\n",
    "lines = np.delete(lines, 0, axis = 0)\n",
    "i = 0\n",
    "\n",
    "for line in lines:\n",
    "    data_line = line.split()\n",
    "    feature = data_line[2:11]\n",
    "    for k in range(9):\n",
    "        if feature[k] == 'NA':\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 1:\n",
    "        flag = 0\n",
    "        continue    # jump out of the loop\n",
    "    X_test[i] = feature    \n",
    "    if data_line[11] == 'FALSE':\n",
    "        y_test[i] = 0\n",
    "    elif data_line[11] == 'TRUE':\n",
    "        y_test[i] = 1\n",
    "    i += 1\n",
    "    \n",
    "X_test = clean_pipeline.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test gcForest on 2018 Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:05,748][cascade_classifier.transform] X_groups_test.shape=[(139566, 9)]\n",
      "[ 2018-11-28 16:50:05,751][cascade_classifier.transform] group_dims=[9]\n",
      "[ 2018-11-28 16:50:05,752][cascade_classifier.transform] X_test.shape=(139566, 9)\n",
      "[ 2018-11-28 16:50:05,755][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(139566, 9)\n",
      "[ 2018-11-28 16:50:06,918][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(139566, 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: 139566, 1 contains: 0.192088\n",
      "y_test_pred: 139566, 1 contains: 0.179220\n",
      "============= 2018 datasets' results on test =============\n",
      "TP= 25013 FP= 0 TN= 112757 FN= 1796\n",
      "precision 1.0 \n",
      "recall 0.9330075720840016 \n",
      "accuracy 0.9871315363340641\n",
      "F1= 0.9653429045579097\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = gc.predict(X_test)\n",
    "\n",
    "y_test_nonezero = np.count_nonzero(y_test)\n",
    "y_test_pred_nonezero = np.count_nonzero(y_test_pred)\n",
    "\n",
    "print(\"y_test: {:d}, 1 contains: {:6f}\".format(len(y_test), y_test_nonezero/len(y_test)))\n",
    "print(\"y_test_pred: {:d}, 1 contains: {:6f}\".format(len(y_test_pred), y_test_pred_nonezero/len(y_test_pred)))\n",
    "\n",
    "\n",
    "print(\"============= 2018 datasets' results on test =============\")\n",
    "gc_f1, gc_accraucy, gc_precision, gc_recall = evaluate(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. train GcForest on batched datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:08,750][cascade_classifier.fit_transform] X_groups_train.shape=[(30936, 27)],y_train.shape=(30936,),X_groups_test.shape=no_test,y_test.shape=no_test\n",
      "[ 2018-11-28 16:50:08,752][cascade_classifier.fit_transform] group_dims=[27]\n",
      "[ 2018-11-28 16:50:08,754][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-11-28 16:50:08,755][cascade_classifier.fit_transform] group_ends=[27]\n",
      "[ 2018-11-28 16:50:08,756][cascade_classifier.fit_transform] X_train.shape=(30936, 27),X_test.shape=(0, 27)\n",
      "[ 2018-11-28 16:50:08,759][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(30936, 27), X_cur_test.shape=(0, 27)\n",
      "[ 2018-11-28 16:50:09,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=99.81%\n",
      "[ 2018-11-28 16:50:09,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=99.84%\n",
      "[ 2018-11-28 16:50:09,783][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=99.77%\n",
      "[ 2018-11-28 16:50:10,111][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=99.85%\n",
      "[ 2018-11-28 16:50:10,438][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=99.79%\n",
      "[ 2018-11-28 16:50:10,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=99.81%\n",
      "[ 2018-11-28 16:50:10,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_0.predict)=99.82%\n",
      "[ 2018-11-28 16:50:10,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_1.predict)=99.79%\n",
      "[ 2018-11-28 16:50:11,156][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_2.predict)=99.77%\n",
      "[ 2018-11-28 16:50:11,384][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_3.predict)=99.77%\n",
      "[ 2018-11-28 16:50:11,608][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_4.predict)=99.89%\n",
      "[ 2018-11-28 16:50:11,610][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_cv.predict)=99.81%\n",
      "[ 2018-11-28 16:50:11,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_0.predict)=99.26%\n",
      "[ 2018-11-28 16:50:11,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_1.predict)=99.24%\n",
      "[ 2018-11-28 16:50:12,064][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_2.predict)=99.47%\n",
      "[ 2018-11-28 16:50:12,212][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_3.predict)=99.34%\n",
      "[ 2018-11-28 16:50:12,352][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_4.predict)=99.21%\n",
      "[ 2018-11-28 16:50:12,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_cv.predict)=99.30%\n",
      "[ 2018-11-28 16:50:12,355][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=99.78%\n",
      "[ 2018-11-28 16:50:12,359][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(30936, 33), X_cur_test.shape=(0, 33)\n",
      "[ 2018-11-28 16:50:12,602][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=99.89%\n",
      "[ 2018-11-28 16:50:12,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=99.79%\n",
      "[ 2018-11-28 16:50:13,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=99.89%\n",
      "[ 2018-11-28 16:50:13,609][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=99.92%\n",
      "[ 2018-11-28 16:50:13,951][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=99.92%\n",
      "[ 2018-11-28 16:50:13,953][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:14,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_0.predict)=99.92%\n",
      "[ 2018-11-28 16:50:14,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_1.predict)=99.76%\n",
      "[ 2018-11-28 16:50:14,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_2.predict)=99.87%\n",
      "[ 2018-11-28 16:50:14,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_3.predict)=99.84%\n",
      "[ 2018-11-28 16:50:15,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_4.predict)=99.95%\n",
      "[ 2018-11-28 16:50:15,124][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_cv.predict)=99.87%\n",
      "[ 2018-11-28 16:50:15,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_0.predict)=99.85%\n",
      "[ 2018-11-28 16:50:15,573][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_1.predict)=99.77%\n",
      "[ 2018-11-28 16:50:15,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_2.predict)=99.90%\n",
      "[ 2018-11-28 16:50:15,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_3.predict)=99.87%\n",
      "[ 2018-11-28 16:50:16,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_4.predict)=99.85%\n",
      "[ 2018-11-28 16:50:16,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_cv.predict)=99.85%\n",
      "[ 2018-11-28 16:50:16,137][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.88%\n",
      "[ 2018-11-28 16:50:16,141][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(30936, 33), X_cur_test.shape=(0, 33)\n",
      "[ 2018-11-28 16:50:16,388][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=99.85%\n",
      "[ 2018-11-28 16:50:16,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=99.87%\n",
      "[ 2018-11-28 16:50:17,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=99.89%\n",
      "[ 2018-11-28 16:50:17,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=99.90%\n",
      "[ 2018-11-28 16:50:17,716][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=99.90%\n",
      "[ 2018-11-28 16:50:17,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:17,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_0.predict)=99.87%\n",
      "[ 2018-11-28 16:50:18,182][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_1.predict)=99.85%\n",
      "[ 2018-11-28 16:50:18,415][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_2.predict)=99.89%\n",
      "[ 2018-11-28 16:50:18,643][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_3.predict)=99.85%\n",
      "[ 2018-11-28 16:50:18,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_4.predict)=99.94%\n",
      "[ 2018-11-28 16:50:18,891][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:19,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_0.predict)=99.82%\n",
      "[ 2018-11-28 16:50:19,307][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_1.predict)=99.73%\n",
      "[ 2018-11-28 16:50:19,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_2.predict)=99.92%\n",
      "[ 2018-11-28 16:50:19,731][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_3.predict)=99.87%\n",
      "[ 2018-11-28 16:50:19,951][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_4.predict)=99.92%\n",
      "[ 2018-11-28 16:50:19,953][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_cv.predict)=99.85%\n",
      "[ 2018-11-28 16:50:19,955][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.88%\n",
      "[ 2018-11-28 16:50:19,959][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(30936, 33), X_cur_test.shape=(0, 33)\n",
      "[ 2018-11-28 16:50:20,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_0.predict)=99.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:20,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_1.predict)=99.90%\n",
      "[ 2018-11-28 16:50:20,952][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_2.predict)=99.89%\n",
      "[ 2018-11-28 16:50:21,284][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_3.predict)=99.87%\n",
      "[ 2018-11-28 16:50:21,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_4.predict)=99.89%\n",
      "[ 2018-11-28 16:50:21,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:21,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_0.predict)=99.92%\n",
      "[ 2018-11-28 16:50:22,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_1.predict)=99.87%\n",
      "[ 2018-11-28 16:50:22,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_2.predict)=99.82%\n",
      "[ 2018-11-28 16:50:22,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_3.predict)=99.85%\n",
      "[ 2018-11-28 16:50:22,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_4.predict)=99.87%\n",
      "[ 2018-11-28 16:50:22,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_cv.predict)=99.87%\n",
      "[ 2018-11-28 16:50:23,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_0.predict)=99.82%\n",
      "[ 2018-11-28 16:50:23,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_1.predict)=99.89%\n",
      "[ 2018-11-28 16:50:23,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_2.predict)=99.92%\n",
      "[ 2018-11-28 16:50:23,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_3.predict)=99.89%\n",
      "[ 2018-11-28 16:50:24,091][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_4.predict)=99.79%\n",
      "[ 2018-11-28 16:50:24,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_cv.predict)=99.86%\n",
      "[ 2018-11-28 16:50:24,095][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.87%\n",
      "[ 2018-11-28 16:50:24,100][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(30936, 33), X_cur_test.shape=(0, 33)\n",
      "[ 2018-11-28 16:50:24,440][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_0.predict)=99.89%\n",
      "[ 2018-11-28 16:50:24,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_1.predict)=99.87%\n",
      "[ 2018-11-28 16:50:25,014][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_2.predict)=99.87%\n",
      "[ 2018-11-28 16:50:25,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_3.predict)=99.85%\n",
      "[ 2018-11-28 16:50:25,698][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_4.predict)=99.92%\n",
      "[ 2018-11-28 16:50:25,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:25,951][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_0.predict)=99.89%\n",
      "[ 2018-11-28 16:50:26,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_1.predict)=99.95%\n",
      "[ 2018-11-28 16:50:26,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_2.predict)=99.79%\n",
      "[ 2018-11-28 16:50:26,644][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_3.predict)=99.89%\n",
      "[ 2018-11-28 16:50:26,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_4.predict)=99.89%\n",
      "[ 2018-11-28 16:50:26,993][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_cv.predict)=99.88%\n",
      "[ 2018-11-28 16:50:27,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_0.predict)=99.82%\n",
      "[ 2018-11-28 16:50:27,384][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_1.predict)=99.90%\n",
      "[ 2018-11-28 16:50:27,568][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_2.predict)=99.84%\n",
      "[ 2018-11-28 16:50:27,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_3.predict)=99.84%\n",
      "[ 2018-11-28 16:50:28,011][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_4.predict)=99.90%\n",
      "[ 2018-11-28 16:50:28,012][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_cv.predict)=99.86%\n",
      "[ 2018-11-28 16:50:28,014][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=99.87%\n",
      "[ 2018-11-28 16:50:28,016][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=99.88%, accuracy_test=0.00%\n"
     ]
    }
   ],
   "source": [
    "X_train_batch_enc = gc.fit_transform(X_train_batch, y_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump\n",
    "with open(\"../pkl/2018_test_batch.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gc, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open(\"../pkl/2018_test_batch.pkl\", \"rb\") as f:\n",
    "    gc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test GcForest on batched valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:28,048][cascade_classifier.transform] X_groups_test.shape=[(15237, 27)]\n",
      "[ 2018-11-28 16:50:28,051][cascade_classifier.transform] group_dims=[27]\n",
      "[ 2018-11-28 16:50:28,052][cascade_classifier.transform] X_test.shape=(15237, 27)\n",
      "[ 2018-11-28 16:50:28,059][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(15237, 27)\n",
      "[ 2018-11-28 16:50:29,122][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(15237, 33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= 2018 datasets' results on 3 batched valid =============\n",
      "TP= 167 FP= 3 TN= 15057 FN= 10\n",
      "precision 0.9823529411764705 \n",
      "recall 0.943502824858757 \n",
      "accuracy 0.999146813677233\n",
      "F1= 0.9625360230547549\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = gc.predict(X_valid_batch)\n",
    "print(\"============= 2018 datasets' results on %d batched valid =============\" %(batch_size))\n",
    "gc_f1, gc_accraucy, gc_precision, gc_recall = evaluate(y_valid_batch, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test gcForest on 2018 batched Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-11-28 16:50:30,534][cascade_classifier.transform] X_groups_test.shape=[(46522, 27)]\n",
      "[ 2018-11-28 16:50:30,541][cascade_classifier.transform] group_dims=[27]\n",
      "[ 2018-11-28 16:50:30,542][cascade_classifier.transform] X_test.shape=(46522, 27)\n",
      "[ 2018-11-28 16:50:30,549][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(46522, 27)\n",
      "[ 2018-11-28 16:50:31,663][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(46522, 33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= 2018 datasets' results on 3 batched test =============\n",
      "TP= 8474 FP= 61 TN= 37523 FN= 464\n",
      "precision 0.9928529584065612 \n",
      "recall 0.9480868203177445 \n",
      "accuracy 0.9887150165513091\n",
      "F1= 0.9699536427631202\n"
     ]
    }
   ],
   "source": [
    "X_test_batch, y_test_batch = Batch(X_test, y_test, batch_size)\n",
    "\n",
    "y_test_pred = gc.predict(X_test_batch)\n",
    "print(\"============= 2018 datasets' results on %d batched test =============\" %(batch_size))\n",
    "gc_f1, gc_accraucy, gc_precision, gc_recall = evaluate(y_test_batch, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gc]",
   "language": "python",
   "name": "conda-env-gc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
